<!-- Template for adding a paper -->
<!--
<div style="margin-bottom: 20px;">
<p>
<b>TITLE</b><br>
AUTHORS<br>
CONFERENCE<br>
[<a href="">pdf</a>]
[<a href="">poster</a>]
[<a href="">slides</a>]
[<a href="">code</a>]
</p>
</div>
-->

<h2>Publications</h2>

<h3>Preprints</h3>

<div style="margin-bottom: 20px;">
<p>
<b>Optimistic PAC Reinforcement Learning: the Instance-Dependent View</b><br>
<b>Andrea Tirinzoni</b>, Aymen Al-Marjani, and Emilie Kaufmann<br>
arXiv preprint, 2022<br>
[<a href="https://arxiv.org/pdf/2207.05852.pdf">pdf</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs</b><br>
<b>Andrea Tirinzoni</b>, Aymen Al-Marjani, and Emilie Kaufmann<br>
arXiv preprint, 2022<br>
[<a href="https://arxiv.org/pdf/2203.09251.pdf">pdf</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>On Elimination Strategies for Bandit Fixed-Confidence Identification</b><br>
<b>Andrea Tirinzoni</b> and Rémy Degenne<br>
arXiv preprint, 2022<br>
[<a href="https://arxiv.org/pdf/2205.10936.pdf">pdf</a>]
[<a href="https://github.com/AndreaTirinzoni/bandit-elimination">code</a>]
</p>
</div>

<h3>Conference papers</h3>

<p style="font-size: 13pt; color: gray;">2021</p>

<div style="margin-bottom: 20px;">
<p>
<b>Reinforcement Learning in Linear MDPs: Constant Regret and Representation Selection</b><br>
Matteo Papini, <b>Andrea Tirinzoni</b>, Aldo Pacchiano, Marcello Restelli, Alessandro Lazaric, and Matteo Pirotta<br>
Advances in Neural Information Processing Systems 34 (NeurIPS), Virtual, 2021<br>
[<a href="https://proceedings.neurips.cc/paper/2021/file/8860e834a67da41edd6ffe8a1c58fa55-Paper.pdf">pdf</a>]
[<a href="files/lsvi_leader_slides.pdf">slides</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Dealing with Misspecification in Fixed-Confidence Linear Top-m Identification</b><br>
Clémence Réda, <b>Andrea Tirinzoni</b>, and Rémy Degenne<br>
Advances in Neural Information Processing Systems 34 (NeurIPS), Virtual, 2021<br>
[<a href="https://arxiv.org/pdf/2111.01479.pdf">pdf</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Leveraging Good Representations in Linear Contextual Bandits</b><br>
Matteo Papini, <b>Andrea Tirinzoni</b>, Marcello Restelli, Alessandro Lazaric, and Matteo Pirotta<br>
International Conference on Machine Learning (ICML), 2021<br>
[<a href="https://arxiv.org/pdf/2104.03781.pdf">pdf</a>]
[<a href="files/leader_slides.pdf">slides</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Meta-Reinforcement Learning by Tracking Task Non-stationarity</b><br>
Riccardo Poiani, <b>Andrea Tirinzoni</b>, and Marcello Restelli<br>
International Joint Conference on Artificial Intelligence (IJCAI), 2021<br>
[<a href="https://arxiv.org/pdf/2105.08834.pdf">pdf</a>]
</p>
</div>

<p style="font-size: 13pt; color: gray;">2020</p>

<div style="margin-bottom: 20px;">
<p>
<b>An Asymptotically Optimal Primal-Dual Incremental Algorithm for Linear Contextual Bandits</b><br>
<b>Andrea Tirinzoni</b>, Matteo Pirotta, Marcello Restelli, and Alessandro Lazaric<br>
Advances in Neural Information Processing Systems 33 (NeurIPS), Vancouver (Canada), 2020<br>
[<a href="https://arxiv.org/pdf/2010.12247.pdf">pdf</a>]
[<a href="files/solid_slides.pdf">slides</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Sequential Transfer in Reinforcement Learning with a Generative Model</b><br>
<b>Andrea Tirinzoni</b>, Riccardo Poiani, and Marcello Restelli<br>
International Conference on Machine Learning (ICML), Vienna (Austria), 2020<br>
[<a href="https://arxiv.org/pdf/2007.00722.pdf">pdf</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>A Novel Confidence-Based Algorithm for Structured Bandits</b><br>
<b>Andrea Tirinzoni</b>, Alessandro Lazaric, and Marcello Restelli<br>
International Conference on Artificial Intelligence and Statistics (AISTATS), Palermo (Italy), 2020<br>
[<a href="https://arxiv.org/pdf/2005.11593.pdf">pdf</a>]
[<a href="files/aistats2020_slides.pdf">slides</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Truly Batch Model-Free Inverse Reinforcement Learning about Multiple Intentions</b><br>
Giorgia Ramponi, Amarildo Likmeta, Alberto Maria Metelli, <b>Andrea Tirinzoni</b>, and Marcello Restelli<br>
International Conference on Artificial Intelligence and Statistics (AISTATS), Palermo (Italy), 2020<br>
[<a href="http://proceedings.mlr.press/v108/ramponi20a/ramponi20a.pdf">pdf</a>]
[<a href="https://github.com/gioramponi/sigma-girl-MIIRL">code</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Gradient-Aware Model-Based Policy-Search</b><br>
Pierluca D'Oro, Alberto Maria Metelli, <b>Andrea Tirinzoni</b>, Matteo Papini, and Marcello Restelli<br>
AAAI Conference on Artificial Intelligence, New York, 2020<br>
[<a href="https://arxiv.org/pdf/1909.04115.pdf">pdf</a>]
[<a href="https://github.com/proceduralia/gradient-aware-code">code</a>]
</p>
</div>

<p style="font-size: 13pt; color: gray;">2019</p>

<div style="margin-bottom: 20px;">
<p>
<b>Transfer of Samples in Policy Search via Multiple Importance Sampling</b><br>
<b>Andrea Tirinzoni</b>, Mattia Salvini, and Marcello Restelli<br>
International Conference on Machine Learning (ICML), Long Beach, 2019<br>
[<a href="http://proceedings.mlr.press/v97/tirinzoni19a/tirinzoni19a.pdf">pdf</a>]
[<a href="files/icml2019_poster.pdf">poster</a>]
[<a href="files/icml2019_slides.pdf">slides</a>]
[<a href="https://github.com/AndreaTirinzoni/transfer-policy-search">code</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Feature Selection via Mutual Information: New Theoretical Insights</b><br>
Mario Beraha, Alberto Maria Metelli, Matteo Papini, <b>Andrea Tirinzoni</b>, and Marcello Restelli<br>
International Joint Conference on Neural Networks (IJCNN), Budapest, 2019<br>
[<a href="https://arxiv.org/pdf/1907.07384.pdf">pdf</a>]
</p>
</div>

<p style="font-size: 13pt; color: gray;">2018</p>

<div style="margin-bottom: 20px;">
<p>
<b>Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes</b><br>
<b>Andrea Tirinzoni</b>, Xiangli Chen, Marek Petrik, and Brian D. Ziebart<br>
Advances in Neural Information Processing Systems (NeurIPS), Montreal, 2018. <b>Spotlight</b> (&lt; 4%)<br>
[<a href="https://papers.nips.cc/paper/8109-policy-conditioned-uncertainty-sets-for-robust-markov-decision-processes.pdf">pdf</a>]
[<a href="files/nips2018_poster_robust.pdf">poster</a>]
[<a href="files/nips2018_slides.pdf">slides</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Transfer of Value Functions via Variational Methods</b><br>
<b>Andrea Tirinzoni</b>, Rafael Rodriguez Sanchez, and Marcello Restelli<br>
Advances in Neural Information Processing Systems (NeurIPS), Montreal, 2018<br>
[<a href="https://papers.nips.cc/paper/2018/file/9023effe3c16b0477df9b93e26d57e2c-Paper.pdf">pdf</a>]
[<a href="files/nips2018_poster_transfer.pdf">poster</a>]
[<a href="https://github.com/AndreaTirinzoni/variational-transfer-rl">code</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Importance Weighted Transfer of Samples in Reinforcement Learning</b><br>
<b>Andrea Tirinzoni</b>, Andrea Sessa, Matteo Pirotta, and Marcello Restelli<br>
International Conference on Machine Learning (ICML), Stockholm, 2018<br>
[<a href="https://arxiv.org/pdf/1805.10886.pdf">pdf</a>]
[<a href="files/icml2018_poster.pdf">poster</a>] 
[<a href="files/icml2018_slides.pdf">slides</a>] 
[<a href="https://github.com/AndreaTirinzoni/iw-transfer-rl">code</a>]
</p>
</div>

<h3>Journal papers</h3>

<div style="margin-bottom: 20px;">
<p>
<b>Risk-Averse Policy Optimization via Risk-Neutral Policy Optimization</b><br>
Lorenzo Bisi, Davide Santambrogio, Federico Sandrelli, <b>Andrea Tirinzoni</b>, Brian D. Ziebart, and Marcello Restelli<br>
Artificial Intelligence, 2022<br>
[<a href="#">link</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Dealing with Multiple Experts and Non-stationarity in Inverse Reinforcement Learning: an Application to Real-life Problems</b><br>
Amarildo Likmeta, Alberto Maria Metelli, Giorgia Ramponi, <b>Andrea Tirinzoni</b>, Matteo Giuliani, and Marcello Restelli<br>
Machine Learning, 2021<br>
[<a href="https://link.springer.com/article/10.1007/s10994-020-05939-8">link</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Combining Reinforcement Learning with Rule-based Controllers for Transparent and General Decision-making in Autonomous Driving</b><br>
Amarildo Likmeta, Alberto Maria Metelli, <b>Andrea Tirinzoni</b>, Riccardo Giol, Marcello Restelli, and Danilo Romano<br>
Robotics and Autonomous Systems, 2020<br>
[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889020304085">link</a>]
</p>
</div>

<h3>Workshop papers</h3>

<div style="margin-bottom: 20px;">
<p>
<b>A Fully Problem-Dependent Regret Lower Bound for Finite-Horizon MDPs</b><br>
<b>Andrea Tirinzoni</b>, Matteo Pirotta, and Alessandro Lazaric<br>
Workshop on Reinforcement Learning Theory @ ICML 2021<br>
[<a href="https://arxiv.org/pdf/2106.13013.pdf">pdf</a>]
</p>
</div>

<h3>Theses</h3>

<div style="margin-bottom: 20px;">
<p>
<b>Exploiting Structure for Transfer in Reinforcement Learning</b><br>
Andrea Tirinzoni (advised by Marcello Restelli)<br>
Ph.D. thesis (information technology)<br>
Politecnico di Milano, 2021<br>
[<a href="https://www.politesi.polimi.it/handle/10589/171185">link</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Adversarial Imitation Learning under Covariate Shift</b><br>
Andrea Tirinzoni (advised by Marcello Restelli)<br>
Master's thesis (computer science and engineering)<br>
Politecnico di Milano, 2017<br>
[<a href="https://www.politesi.polimi.it/bitstream/10589/136073/1/Andrea_Tirinzoni_Thesis.pdf">pdf</a>]
</p>
</div>

<div style="margin-bottom: 20px;">
<p>
<b>Adversarial Inverse Reinforcement Learning with Changing Dynamics</b><br>
Andrea Tirinzoni (advised by Brian Ziebart)<br>
Master's thesis (computer science)<br> 
University of Illinois at Chicago, 2017<br>
[<a href="https://indigo.uic.edu/articles/thesis/Adversarial_Inverse_Reinforcement_Learning_with_Changing_Dynamics/10935227">link</a>]
</p>
</div>